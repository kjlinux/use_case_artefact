{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse Exploratoire - Fashion Store Sales\n",
    "\n",
    "Ce notebook presente l'analyse exploratoire du jeu de donnees des ventes d'un site e-commerce de mode. L'objectif est d'examiner la structure du fichier, identifier les entites metier principales, et mettre en evidence les redondances et anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('../data/fashion_store_sales.csv')\n",
    "print(f\"Dimensions : {df.shape[0]} lignes, {df.shape[1]} colonnes\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Structure du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    'type': df.dtypes,\n",
    "    'non_null': df.notna().sum(),\n",
    "    'null': df.isna().sum(),\n",
    "    'unique': df.nunique(),\n",
    "    'exemple': df.iloc[0]\n",
    "})\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Identification des entites metier\n",
    "\n",
    "Le fichier CSV est un fichier plat (denormalise) qui contient plusieurs entites metier melangees dans chaque ligne. En analysant les cardinalites, on identifie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = {\n",
    "    'Articles de vente (item_id)': df['item_id'].nunique(),\n",
    "    'Ventes (sale_id)': df['sale_id'].nunique(),\n",
    "    'Produits (product_id)': df['product_id'].nunique(),\n",
    "    'Clients (customer_id)': df['customer_id'].nunique(),\n",
    "    'Canaux (channel)': df['channel'].nunique(),\n",
    "}\n",
    "for k, v in entities.items():\n",
    "    print(f\"{k}: {v} valeurs uniques\")\n",
    "\n",
    "print(f\"\\nChaque ligne = 1 article de vente (grain du fichier)\")\n",
    "print(f\"Nombre moyen d'articles par vente : {df.shape[0] / df['sale_id'].nunique():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_per_sale = df.groupby('sale_id')['item_id'].count()\n",
    "print(\"Distribution du nombre d'articles par vente :\")\n",
    "print(items_per_sale.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyse de redondance\n",
    "\n",
    "Dans le fichier plat, les attributs client sont repetes a chaque ligne ou le client apparait. Idem pour les produits. C'est la redondance typique qu'on elimine par la normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_cols = ['customer_id', 'first_name', 'last_name', 'email', 'gender', 'age_range', 'signup_date', 'country']\n",
    "product_cols = ['product_id', 'product_name', 'category', 'brand', 'color', 'size', 'catalog_price', 'cost_price']\n",
    "\n",
    "nb_customer_rows = df.shape[0]\n",
    "nb_unique_customers = df['customer_id'].nunique()\n",
    "nb_unique_products = df['product_id'].nunique()\n",
    "\n",
    "print(f\"Attributs client repetes en moyenne {nb_customer_rows / nb_unique_customers:.1f}x\")\n",
    "print(f\"Attributs produit repetes en moyenne {nb_customer_rows / nb_unique_products:.1f}x\")\n",
    "print(f\"\\nSur 2253 lignes, seuls {nb_unique_customers} ensembles client et {nb_unique_products} ensembles produit sont distincts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(1)\n",
    "missing_df = pd.DataFrame({'manquants': missing, 'pourcentage': missing_pct})\n",
    "missing_df[missing_df['manquants'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_str = (df == '').sum()\n",
    "for col in ['first_name', 'last_name', 'email', 'total_amount']:\n",
    "    null_count = df[col].isna().sum()\n",
    "    empty_count = (df[col].astype(str).str.strip() == '').sum() if null_count == 0 else null_count\n",
    "    print(f\"{col}: {empty_count} valeurs manquantes ou vides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constat :** Environ 180 first_name, 224 email et 225 total_amount sont manquants. Le total_amount est derivable (somme des item_total par vente), donc ce n'est pas une perte de donnees. Les noms et emails manquants suggerent des clients partiellement anonymes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Coherence de product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_attrs = ['product_name', 'category', 'brand', 'color', 'size', 'catalog_price', 'cost_price']\n",
    "consistency = df.groupby('product_id')[product_attrs].nunique()\n",
    "inconsistent = consistency[consistency.gt(1).any(axis=1)]\n",
    "\n",
    "if inconsistent.empty:\n",
    "    print(\"Tous les product_id sont coherents avec leurs attributs.\")\n",
    "else:\n",
    "    print(f\"{len(inconsistent)} product_id incoherents detectes :\")\n",
    "    print(inconsistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_attrs = ['gender', 'age_range', 'signup_date', 'country']\n",
    "cust_consistency = df.groupby('customer_id')[customer_attrs].nunique()\n",
    "cust_inconsistent = cust_consistency[cust_consistency.gt(1).any(axis=1)]\n",
    "\n",
    "if cust_inconsistent.empty:\n",
    "    print(\"Tous les customer_id sont coherents avec leurs attributs.\")\n",
    "else:\n",
    "    print(f\"{len(cust_inconsistent)} customer_id incoherents :\")\n",
    "    print(cust_inconsistent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Valeurs du domaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['channel', 'channel_campaigns', 'category', 'brand', 'color', 'size', 'gender', 'age_range', 'country']\n",
    "\n",
    "for col in categorical:\n",
    "    print(f\"\\n--- {col} ({df[col].nunique()} valeurs) ---\")\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations :**\n",
    "- Une seule marque (Tiva) et un seul genre (Female) dans tout le dataset\n",
    "- 2 canaux avec mapping 1:1 vers les campagnes\n",
    "- La colonne size melange tailles textiles (XS, S, M, L, XL) et pointures numeriques (35, 36, 38, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Mapping channel / channel_campaigns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_mapping = df[['channel', 'channel_campaigns']].drop_duplicates()\n",
    "print(\"Mapping channel -> channel_campaigns :\")\n",
    "print(channel_mapping.to_string(index=False))\n",
    "print(f\"\\nRelation 1:1 confirmee : chaque canal a exactement une campagne associee.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyse des remises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discounted = df[df['discount_applied'] > 0]\n",
    "print(f\"Lignes avec remise : {len(discounted)} sur {len(df)} ({len(discounted)/len(df)*100:.1f}%)\")\n",
    "print(f\"\\nValeurs distinctes de discount_percent :\")\n",
    "print(df['discount_percent'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Verification des formules de prix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['check_unit_price'] = (df['original_price'] - df['discount_applied']).round(2)\n",
    "unit_price_ok = (df['check_unit_price'] == df['unit_price']).all()\n",
    "print(f\"unit_price = original_price - discount_applied : {unit_price_ok}\")\n",
    "\n",
    "df['check_item_total'] = (df['quantity'] * df['unit_price']).round(2)\n",
    "item_total_ok = (df['check_item_total'] == df['item_total']).all()\n",
    "print(f\"item_total = quantity * unit_price : {item_total_ok}\")\n",
    "\n",
    "df['check_discounted'] = (df['discount_applied'] > 0).astype(int)\n",
    "discounted_ok = (df['check_discounted'] == df['discounted']).all()\n",
    "print(f\"discounted = 1 si discount_applied > 0 : {discounted_ok}\")\n",
    "\n",
    "print(\"\\nConclusion : tous les champs derives sont calculables a partir de original_price, discount_applied et quantity.\")\n",
    "print(\"Ils peuvent etre supprimes en DKNF et recalcules via une vue.\")\n",
    "\n",
    "df.drop(columns=['check_unit_price', 'check_item_total', 'check_discounted'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Distributions statistiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "df['category'].value_counts().plot(kind='bar', ax=axes[0, 0], color='steelblue')\n",
    "axes[0, 0].set_title('Repartition par categorie')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "df['country'].value_counts().plot(kind='bar', ax=axes[0, 1], color='coral')\n",
    "axes[0, 1].set_title('Repartition par pays')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "df['channel'].value_counts().plot(kind='bar', ax=axes[1, 0], color='seagreen')\n",
    "axes[1, 0].set_title('Repartition par canal')\n",
    "axes[1, 0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "df['age_range'].value_counts().sort_index().plot(kind='bar', ax=axes[1, 1], color='mediumpurple')\n",
    "axes[1, 1].set_title('Repartition par tranche d\\'age')\n",
    "axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "df['original_price'].hist(bins=30, ax=axes[0], color='steelblue', edgecolor='white')\n",
    "axes[0].set_title('Distribution des prix originaux')\n",
    "axes[0].set_xlabel('Prix')\n",
    "\n",
    "df['sale_date'] = pd.to_datetime(df['sale_date'])\n",
    "daily_sales = df.groupby('sale_date')['sale_id'].nunique()\n",
    "daily_sales.plot(ax=axes[1], color='coral')\n",
    "axes[1].set_title('Nombre de ventes par jour')\n",
    "axes[1].set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Plage de dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Premiere date : {df['sale_date'].min()}\")\n",
    "print(f\"Derniere date : {df['sale_date'].max()}\")\n",
    "print(f\"Nombre de jours distincts : {df['sale_date'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Synthese des anomalies et observations\n",
    "\n",
    "| Observation | Detail |\n",
    "|---|---|\n",
    "| Valeurs manquantes | 180 first_name, 224 email, 225 total_amount |\n",
    "| Marque unique | Toutes les lignes ont brand = Tiva |\n",
    "| Genre unique | Toutes les lignes ont gender = Female |\n",
    "| Tailles mixtes | Melange de tailles textiles et pointures numeriques |\n",
    "| Mapping 1:1 channel/campaign | App Mobile -> App Mobile, E-commerce -> Website Banner |\n",
    "| Remises limitees | Seulement 10% et 30%, appliquees sur 9.9% des lignes |\n",
    "| Champs derivables | unit_price, discount_percent, discounted, item_total, total_amount |\n",
    "| Redondance massive | Attributs client repetes ~4x, attributs produit ~4.5x |\n",
    "| Ventes multi-articles | 905 ventes contiennent 2253 articles (2-3 articles par vente) |\n",
    "\n",
    "Ces constats motivent directement la normalisation en 3NF puis DKNF pour eliminer la redondance et garantir l'integrite des donnees."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
